---
layout: post
title: Lecture 18
---


# Autoregulation

We will continue our discussion of autoregulating genetic networks. Specifically, we will continue talking about autorepression.

## Autorepression

Recall that there are two advantages of autorepression.

1. Reduces response time.
2. Buffers fluctuations.

### Noise Reduction (buffer fluctuations)

Consider a small fluctuation $$\epsilon$$ from the steady-state concentration $$x^*$$.

$$ x = x^* + \epsilon $$

$$ \dot{x} = \dot{\epsilon} = \underbrace{f_-(x^*+\epsilon)-r(x^*+\epsilon)}_{F(x^*+\epsilon)} $$

Let's make a Taylor series expansion of the time derivative...

$$ \dot{\epsilon}=\underbrace{F(x^*)}_{=0}+\epsilon F'(x^*)+\frac{1}{2}\epsilon^2F''(x^*)+... $$

We neglect terms of order $$\epsilon^2$$.

$$ \Rightarrow \dot{\epsilon}=F'(x^*)\epsilon \\ \therefore \epsilon(t)=\epsilon(0)e^{F'(x^*)t}$$

$$\begin{align*}
F'(x^*)<0 &\Rightarrow \text{ decay (stable)} \\
F'(x^*)>0 &\Rightarrow \text{ growth (unstable)}
\end{align*}$$

In our case $$F'(x^*)<0$$. So fluctuations in the number of proteins will decay exponentially leading to a stable stead-state concentration of protein.

Now lets derive the stochastic model for autorepression gene regulation.

# Stochastic Model of Autorepression

$$
\dot{p}_0 = rp_1-f_0p_0 \\
\dot{p}_n = f_{n-1}p_{n-1}+r(n+1)p_{n+1}-f_np_n-rnp_n \ \ \text{ for n}\geq\text{1}
$$

$$ f_n = k \frac{n^h_0}{n^h_0+n^h} \\ \left[f_n\right] = \frac{1}{\text{time}}$$

## Steady-State Solution

In steady the time derivative of the probabilities will be equal to zero.

### For $$\ n=0$$

$$ 0= rp_1-f_0p_0 \\ \Rightarrow p_1=\frac{f_0}{r}p_0 $$

### For $$\ n=1$$

$$
0 = f_{0}p_{0}+2rp_{2}-f_1p_1-rp_1 \\
p_2 = \frac{f_1}{2r}p_1 \\ \Rightarrow p_2 =\frac{1}{2}\frac{f_0f_1}{r^2}p_0
$$

### For $$\ n=2$$

$$
0 = f_{1}p_{1}+3rp_{3}-f_2p_2-2rp_2 \\
p_3 = \frac{f_2}{3r}p_2 \\ \Rightarrow p_3 = \frac{1}{2\cdot 3}\frac{f_0f_1f_2}{r^3}p_0
$$

A pattern emerges...

$$ p_n = \frac{p_0}{n!r^n} \prod_{j=0}^{n-1}f_j $$

So we now have an exact expression for the probability distribution. However, this form is very unwieldy.

# Autoactivation

This is the opposite of autorepression we can hypothesize that it has the following features:

1. Increases the response time.
2. Increases fluctuations due to noise.
3. Can lead to bi-stability.

## 1. Increase Response Time

Lets examine how the response time increases for an autoactivation process.

$$ \dot{x} = f_+(x)-rx \\ f_+(x)=\frac{k_0}{V}+\frac{x^h}{K_d^h+x^h}$$

$$ k_0 = \text{ Expression rate in the absence of the activator} $$

This differential equation is hard! So lets not make some approximations to make things easier to solve. We will assume non-cooperativity and that there is strong activation. This translates into the following contraints:

$$ h = 1 \ , \ \ \ K_d>>x $$

$$
\Rightarrow \dot{x} = \frac{k_0}{V}+\frac{k}{K_dV}x-rx \\
\dot{x} = \frac{k_0}{V}- \underbrace{\left(r-\frac{k}{K_dV}\right)}_{r_\text{eff}}x
$$

$$ \therefore x(t) = \left[x(0)-x^*\right]e^{-r_\text{eff}t}+x^* $$

$$ r_\text{eff}<r \ \Rightarrow \ \tau_\text{eff}>\tau $$

So the response time has increased in comparison with. the unregulated case. This increase in response time will lead to a broader probability distribution.


> Written with [StackEdit](https://stackedit.io/).
